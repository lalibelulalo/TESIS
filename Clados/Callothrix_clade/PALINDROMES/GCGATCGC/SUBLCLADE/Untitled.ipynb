{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f618218",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "\n",
    "SEQUENCES_PATH = 'RECONSTRUCCIONES/' #'Only_ORTHOLOGUES/' #sys.argv[1] #\n",
    "pattern = 'GCGATCGC' #sys.argv[2] #\n",
    "SPP = 'SubClade'#sys.argv[3]\n",
    "OUT = 'THIRD'#sys.argv[4]\n",
    "\n",
    "output_file = '' ## Nombre del archivo de salida\n",
    "output_file = '.'.join(['Orthologues_Palindrome_sites.AllFrames',OUT,'txt'])\n",
    "output = open (output_file, 'w') ## Abrimos el archivo de salida\n",
    "output.write('FILE\\tSpp\\tSTART\\tEND\\tReadingFrame\\tOrthLength\\tPAL\\tAA\\n')\n",
    "codonErrors = '.'.join(['CodonErrors',SPP,'txt'])\n",
    "ErrorFile = open (codonErrors, 'w')\n",
    "\n",
    "if SEQUENCES_PATH.endswith(\"/\"): ## Esta parte la pongo por si corro este codigo en la terminal\n",
    "    SequencesPath = re.sub('/', '', SEQUENCES_PATH) ## De este modo evito errores en el argumento path \n",
    "    SequencesDir = str(SEQUENCES_PATH)\n",
    "else:\n",
    "    SequencesPath = SEQUENCES_PATH\n",
    "    SequencesDir = str(\"\".join ([SEQUENCES_PATH,'/']))\n",
    "\n",
    "def translate(seq):\n",
    "    table = {\n",
    "        'ATA':'I', 'ATC':'I', 'ATT':'I', 'ATG':'M',\n",
    "        'ACA':'T', 'ACC':'T', 'ACG':'T', 'ACT':'T',\n",
    "        'AAC':'N', 'AAT':'N', 'AAA':'K', 'AAG':'K',\n",
    "        'AGC':'S', 'AGT':'S', 'AGA':'R', 'AGG':'R',\n",
    "        'CTA':'L', 'CTC':'L', 'CTG':'L', 'CTT':'L',\n",
    "        'CCA':'P', 'CCC':'P', 'CCG':'P', 'CCT':'P',\n",
    "        'CAC':'H', 'CAT':'H', 'CAA':'Q', 'CAG':'Q',\n",
    "        'CGA':'R', 'CGC':'R', 'CGG':'R', 'CGT':'R',\n",
    "        'GTA':'V', 'GTC':'V', 'GTG':'V', 'GTT':'V',\n",
    "        'GCA':'A', 'GCC':'A', 'GCG':'A', 'GCT':'A',\n",
    "        'GAC':'D', 'GAT':'D', 'GAA':'E', 'GAG':'E',\n",
    "        'GGA':'G', 'GGC':'G', 'GGG':'G', 'GGT':'G',\n",
    "        'TCA':'S', 'TCC':'S', 'TCG':'S', 'TCT':'S',\n",
    "        'TTC':'F', 'TTT':'F', 'TTA':'L', 'TTG':'L',\n",
    "        'TAC':'Y', 'TAT':'Y', 'TAA':'_', 'TAG':'_',\n",
    "        'TGC':'C', 'TGT':'C', 'TGA':'_', 'TGG':'W',\n",
    "        '---':'-',\n",
    "    }\n",
    "    protein =\"\"\n",
    "    if len(seq)%3 == 0:\n",
    "        for i in range(0, len(seq), 3):\n",
    "            codon = seq[i:i + 3]\n",
    "            protein+= table[codon]\n",
    "    return protein\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfe003c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Orthologues = [x for x in os.listdir(SequencesDir) if x.endswith(\".phy\")] ## creo un arreglo con todos los ortólogos de la carpeta\n",
    "#pattern = '[cC][-]*[gG][-]*[gG][-]*[cC][-]*[gG][-]*[cC][-]*[cC][-]*[gG]'\n",
    "pattern = re.sub('G', '[gG][-]*', pattern)\n",
    "pattern = re.sub('C', '[cC][-]*', pattern)\n",
    "pattern = re.sub('T', '[tT][-]*', pattern)\n",
    "pattern = re.sub('A', '[aA][-]*', pattern)\n",
    "pattern = pattern[:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d7ddf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for orthologue in Orthologues:\n",
    "orthologue = '9567_glutathione_S-transf...codon.alg.fasta.phy.RECONSTRUCTION.fasta.phy'\n",
    "file = re.sub('\\.fna\\.awk1\\.mafft\\.phy', '', orthologue)\n",
    "FNA = str(\"\".join ([SequencesDir,orthologue]))\n",
    "spps = [str(record.description) for record in SeqIO.parse(open(FNA),'phylip')]## Guardo las especies (del enacbezado) en una lista\n",
    "sequencesDict = {str(record.description):str(record.seq) for record in SeqIO.parse(open(FNA),'phylip')}## Creo un diccionario. La llave es la especie y el valor es la secuencia nucleotídica\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53146019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'336-3'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spps[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "058065bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sites = [match.span()[0] for match in re.finditer(pattern, sequencesDict[spps[0]])]## Busco el INICIO del patron unicamente en la llave (especie) que me interesa. Guardo estos sitios en un arreglo.\n",
    "EndSites = [match.span()[1] for match in re.finditer(pattern, sequencesDict[spps[0]])]## Busco el FINAL del patron unicamente en la llave (especie) que me interesa. Guardo estos sitios en un arreglo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0bd1b73d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[181]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EndSites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7d6db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Orthologues = [x for x in os.listdir(SequencesDir) if x.endswith(\".phy\")] ## creo un arreglo con todos los ortólogos de la carpeta\n",
    "#pattern = '[cC][-]*[gG][-]*[gG][-]*[cC][-]*[gG][-]*[cC][-]*[cC][-]*[gG]'\n",
    "pattern = re.sub('G', '[gG][-]*', pattern)\n",
    "pattern = re.sub('C', '[cC][-]*', pattern)\n",
    "pattern = re.sub('T', '[tT][-]*', pattern)\n",
    "pattern = re.sub('A', '[aA][-]*', pattern)\n",
    "pattern = pattern[:-4]\n",
    "\n",
    "\n",
    "k=0\n",
    "l=0\n",
    "l1=0\n",
    "l2=0\n",
    "l3=0\n",
    "RF1=0\n",
    "RF2=0\n",
    "RF3=0\n",
    "strangecodons=0\n",
    "try:\n",
    "    for orthologue in Orthologues:\n",
    "        file = re.sub('\\.fna\\.awk1\\.mafft\\.phy', '', orthologue)\n",
    "        FNA = str(\"\".join ([SequencesDir,orthologue]))\n",
    "        spps = [str(record.description) for record in SeqIO.parse(open(FNA),'phylip')]## Guardo las especies (del enacbezado) en una lista\n",
    "        sequencesDict = {str(record.description):str(record.seq) for record in SeqIO.parse(open(FNA),'phylip')}## Creo un diccionario. La llave es la especie y el valor es la secuencia nucleotídica\n",
    "        Sites = [match.span()[0] for match in re.finditer(pattern, sequencesDict[SPP])]## Busco el INICIO del patron unicamente en la llave (especie) que me interesa. Guardo estos sitios en un arreglo.\n",
    "        EndSites = [match.span()[1] for match in re.finditer(pattern, sequencesDict[SPP])]## Busco el FINAL del patron unicamente en la llave (especie) que me interesa. Guardo estos sitios en un arreglo.\n",
    "        \n",
    "        j=0 ## Iniciamos contador en 0. El primer sitio.\n",
    "        for site in Sites:\n",
    "            k += 1\n",
    "            for spp in spps:    \n",
    "                end = EndSites[j]\n",
    "                kmer = sequencesDict[spp][site:end]\n",
    "                OrthLength = len(sequencesDict[spp])\n",
    "                start = site\n",
    "                mod1 = (start+1+2) % 3\n",
    "                mod2 = (start+1+1) % 3\n",
    "                mod3 = (start+1+0) % 3\n",
    "                if mod1 == 0:\n",
    "                    RF = 1\n",
    "                    RF1+=1\n",
    "                elif mod2 == 0:\n",
    "                    RF = 2\n",
    "                    RF2+=1\n",
    "                elif mod3 == 0:\n",
    "                    RF = 3\n",
    "                    RF3+=1\n",
    "                    \n",
    "                if len(kmer)==8 and RF ==1:\n",
    "                    l += 1\n",
    "                    l1 += 1\n",
    "                    AAstart = int(((start+3)/3)-1)\n",
    "                    AAend = AAstart+3\n",
    "                    AAseq = sequencesDict[spp]\n",
    "                    AA = translate(AAseq)[AAstart:AAend]\n",
    "                    codon1 = sequencesDict[spp][site:site+3]\n",
    "                    codon2 = sequencesDict[spp][site+3:site+3+3]\n",
    "                    codon3 = sequencesDict[spp][site+3+3:site+3+3+3]\n",
    "                    word = \" \".join ([codon1,codon2,codon3])\n",
    "                    ##print ('{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\n'.format(file,spp,start+1,end,RF,OrthLength,word,AA))\n",
    "                    output.write('{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\n'.format(file,spp,start+1,end,RF,OrthLength,word,AA))\n",
    "                    #outputM1.write('{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\n'.format(file,spp,start+1,end,RF,OrthLength,word,AA))\n",
    "                elif len(kmer)==8 and RF ==2:\n",
    "                    l += 1\n",
    "                    l2 += 1\n",
    "                    AAstart = int(((start+2)/3)-1)\n",
    "                    AAend = AAstart+3\n",
    "                    AAseq = sequencesDict[spp]\n",
    "                    AA = translate(AAseq)[AAstart:AAend]\n",
    "                    codon1 = sequencesDict[spp][site-1:site-1+3]\n",
    "                    codon2 = sequencesDict[spp][site-1+3:site-1+3+3]\n",
    "                    codon3 = sequencesDict[spp][site-1+3+3:site-1+3+3+3]\n",
    "                    word = \" \".join ([codon1,codon2,codon3])\n",
    "                    ##print ('{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\n'.format(file,spp,start+1,end,RF,OrthLength,word,AA))\n",
    "                    output.write('{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\n'.format(file,spp,start+1,end,RF,OrthLength,word,AA))\n",
    "                    #outputM2.write('{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\n'.format(file,spp,start+1,end,RF,OrthLength,word,AA))\n",
    "                elif len(kmer)==8 and RF ==3:\n",
    "                    l += 1\n",
    "                    l3 += 1\n",
    "                    AAstart = int(((start+1)/3)-1)\n",
    "                    AAend = AAstart+4\n",
    "                    AAseq = sequencesDict[spp]\n",
    "                    AA = translate(AAseq)[AAstart:AAend]\n",
    "                    codon1 = sequencesDict[spp][site-2:site-2+3]\n",
    "                    codon2 = sequencesDict[spp][site-2+3:site-2+3+3]\n",
    "                    codon3 = sequencesDict[spp][site-2+3+3:site-2+3+3+3]\n",
    "                    codon4 = sequencesDict[spp][site-2+3+3+3:site-2+3+3+3+3]\n",
    "                    word = \" \".join ([codon1,codon2,codon3,codon4])\n",
    "                    ##print ('{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\n'.format(file,spp,start+1,end,RF,OrthLength,word,AA))\n",
    "                    output.write('{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\n'.format(file,spp,start+1,end,RF,OrthLength,word,AA))\n",
    "                    #outputM3.write('{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\n'.format(file,spp,start+1,end,RF,OrthLength,word,AA))\n",
    "            j += 1\n",
    "            ##print ('_________________________________________________________________________\\n')\n",
    "            #k = k + len(Sites)\n",
    "except KeyError as e:\n",
    "    strangecodons += 1\n",
    "    ErrorFile.write(\"-----------------------------------\\n\")\n",
    "    ErrorFile.write(\"There is a strange codon in orthologue \\\"{}\\\". Check it.\\n\".format(orthologue))\n",
    "    ErrorFile.write(\"The strange codon is: {}.\\n\".format(e.args[0]))\n",
    "    ErrorFile.write(\"-----------------------------------\\n\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6889c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "output.close()\n",
    "ErrorFile.close()\n",
    "#outputM1.close()\n",
    "#outputM2.close()\n",
    "#outputM3.close()\n",
    "\n",
    "RF1I = int(((RF1/len(spps))-(l1/len(spps))))\n",
    "RF2I = int(((RF2/len(spps))-(l2/len(spps))))\n",
    "RF3I = int(((RF3/len(spps))-(l3/len(spps))))\n",
    "RFAU = int(l/(len(spps)))\n",
    "RF1U = int(l1/len(spps))\n",
    "RF2U = int(l2/len(spps))\n",
    "RF3U = int(l3/len(spps))\n",
    "RFAI = int(k -(l/(len(spps))))\n",
    "\n",
    "output_file2 = '_'.join([SPP,'Reading_Frames.counts'])\n",
    "#RFoutput = open ('Reading_Frames.counts', 'w') ## Abrimos el archivo de salida\n",
    "RFoutput = open (output_file2, 'w')\n",
    "\n",
    "RFoutput.write(\"{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\".format(SPP,RF1U,RF2U,RF3U,RF1I,RF2I,RF3I,RFAU,RFAI))\n",
    "RFoutput.close()\n",
    "\n",
    "print (\"RF1:\")\n",
    "print (\"{}\\tinterrupted sites.\".format(RF1I))\n",
    "print (\"{}\\tUNinterrupted sites.\\n\".format(RF1U))\n",
    "\n",
    "print (\"RF2:\")\n",
    "print (\"{}\\tinterrupted sites.\".format(RF2I))\n",
    "print (\"{}\\tUNinterrupted sites.\\n\".format(RF2U))\n",
    "\n",
    "print (\"RF3:\")\n",
    "print (\"{}\\tinterrupted sites.\".format(RF3I))\n",
    "print (\"{}\\tUNinterrupted sites.\\n\".format(RF3U))\n",
    "print (\"-----------------------------------\")\n",
    "print (\"There are {}\\tinterrupted sites.\".format(RFAI))\n",
    "print (\"There are {}\\tUNinterrupted sites.\".format(RFAU))\n",
    "print (\"TOTAL: {}\\tsites.\\n\".format(int(k)-strangecodons))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
